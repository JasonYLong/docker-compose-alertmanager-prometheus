## 容器监控解决方案 Alertmanager Prometheus Grafana Exporter cAdvisor


# 1.运行 Node Exporter
```
创建网络my_net2
   # docker network create --driver bridge --subnet 172.22.17.0/24 --gateway 172.22.17.1 my_net2
   # brctl show
   # docker inspect my_net2

在两个 host 上执行如下命令：
docker run -d -p 9100:9100 \
  -v "/proc:/host/proc" \
  -v "/sys:/host/sys" \
  -v "/:/rootfs" \
  --net=my_net2 \
  --cap-add=SYS_TIME \
  -h node-exporter \
  --name=node-exporter \
  prom/node-exporter \
  --path.procfs /host/proc \
  --path.sysfs /host/sys \
  --collector.filesystem.ignored-mount-points "^/(sys|proc|dev|host|etc)($|/)"

Node Exporter 启动后，将通过 9100 提供 host 的监控数据。在浏览器中通过 http://IP:9100/metrics 测试一下。
   
``` 

# 2.运行 cAdvisor
```
在两个 host 上执行如下命令：
docker run \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:rw \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  -p 8080:8080 \
  --detach=true \
  -h cadvisor \
  --name=cadvisor \
  --net=my_net2 \
  google/cadvisor:latest

这里我们使用了 --net=host，这样 Prometheus Server 可以直接与 cAdvisor 通信。

cAdvisor 启动后，将通过 8080 提供 host 的监控数据。在浏览器中通过 http://IP:8080/metrics 测试一下。

如果启动cAdvisor报错
docker logs container_id
F0615 05:57:12.024944       1 cadvisor.go:156] Failed to start container manager: inotify_add_watch /sys/fs/cgroup/cpuacct,cpu: no such file or directory

fixed:
    mount -o remount,rw '/sys/fs/cgroup'
    ln -s /sys/fs/cgroup/cpu,cpuacct /sys/fs/cgroup/cpuacct,cpu
```

# 3.altermanger 邮件报警
```
配置报警方式的配置文件 alertmanager.yml

alertmanager.yml
---------------
vi alertmanager.yml
global:
   smtp_smarthost: 'smtp.qq.com:587'
   smtp_from: 'XXX@qq.com'
   smtp_auth_username: 'XXX@qq.com'
   smtp_auth_password: 'XXXX'
route:
   group_wait: 30s
   group_interval: 1m
   repeat_interval: 1m
   group_by: ['alertname']
   receiver: default-email
   routes:
   - match: 
       user: jason
     receiver: email

   - match:
       user: long
     receiver: slack    

receivers:
  - name: 'slack'
    slack_configs:
      - api_url: "https://hooks.slack.com/services/XXXX"
        channel: "#prometheus"
        text: "{{ range .Alerts }} {{ .Annotations.description}}\n {{end}} {{ .CommonAnnotations.username}} <{{.CommonAnnotations.link}}| click here>"
        title: "{{.CommonAnnotations.summary}}"
        title_link: "{{.CommonAnnotations.link}}"
        color: "{{.CommonAnnotations.color}}"

  - name: 'email'
    email_configs:
    - to: 'long.yuan@foxmail.com'

  - name: 'default-email'
    email_configs:
    - to: 'XXXX@139.com'

-----------------------------
匹配到 user: jason  发送 email 给 long.yuan@foxmail.com
匹配到 user: long   发送 slack 到 AppOps workstation
什么都没匹配到，就执行 default-receiver 发送 email 给 15997419757@139.com

slack: 配置方法
1. 申请slack账号
2. 创建channel
3. 添加app incoming- ,点击View--> Webhook URL [复制这里得link，后面有用]

QQ邮箱生成
设置-->账户-->POP3/SMTP服务，启用
点击“生成授权码” 这里得授权码就是登陆QQ时用的 

启动alertmanager容器
docker run -d -p 9093:9093 -v /root/docker/prometheus/alertmanager.yml:/etc/alertmanager/alertmanager.yml --net=my_net2 -h alertmanager --name alertmanager prom/alertmanager

如果配置文件加载成功，在 http://IP:9093/#/status 会看到Config中是你的配置文件中的配置

```

# 4.运行 Prometheus Server
```
---------------
配置报警规则文件（我配置了三个，node_down.yml为 prometheus targets 监控，memory_over.yml节点内存使用率监控, load_over.yml负载过高监控）,并在prometheus.yml中启用报警
prometheus targets 监控报警参考配置(node_down.yml)：
---------
vi node_down.yml
groups:
- name: node_down
  rules:
  - alert: InstanceDown
    expr: up == 0
    for: 5m
    labels:
      user: jason
    annotations:
      summary: "Cadvisor Instance down"
      description: "{{$labels.instance}}: down for more than 1 minutes."
      link: "http://IP/graph?g0.range_input=1h&g0.expr=up%20%3D%3D%200&g0.tab=1"
      color: "#ff0000"
      username: "@Jason"

---------
节点内存使用率监控报警参考配置（memory_over.yml）
-------
vi memory_over.yml
groups:
- name: memory_over
  rules:
  - alert: NodeMemoryUsage
    expr: (node_memory_MemTotal_bytes - (node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes )) / node_memory_MemTotal_bytes * 100 > 30
    for: 5m
    labels:
      user: long
    annotations:
      summary: "High Memory usage detected"
      description: "{{$labels.instance}}: Memory usage is above 30% (current value is:{{ $value }})"
      link: "http://IP:9090/graph?g0.range_input=1h&g0.expr=(node_memory_MemTotal_bytes%20-%20(node_memory_MemFree_bytes%2Bnode_memory_Buffers_bytes%2Bnode_memory_Cached_bytes%20))%20%2F%20node_memory_MemTotal_bytes%20*%20100%20%3E%2030&g0.tab=1"
      color: "#0000ff"
      username: "@long"

---------------
prometheus targets 监控报警参考配置(load_over.yml)：
---------
vi load_over.yml
groups:
- name: load_over
  rules:
  - alert: load_over
    expr: node_load1 > 0.8
    for: 5m
    labels:
      user: jasonlong
    annotations:
      summary: "OS load is over 0.8"
      description: "{{$labels.instance}}: OS load is over 0.8."
      link: "http://IP:9090/graph?g0.range_input=1h&g0.expr=node_load1%20%3E%200.8&g0.tab=1"
      color: "#ff0000"
      username: "@jasonlong"

修改prometheus配置文件prometheus.yml，开启报警功能，添加报警规则配置文件
vi prometheus.yml
global:
  scrape_interval:     15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # Evaluate rules every 15 seconds.

  # Attach these extra labels to all timeseries collected by this Prometheus instance.
  external_labels:
    monitor: 'codelab-monitor'
#rule_files:
#  - 'prometheus.rules'

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets: ["alertmanager:9093"]
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "node_down.yml"
  - "memory_over.yml"
  - "load_over.yml"

scrape_configs:
  - job_name: 'prometheus'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    static_configs:
      - targets: ['prometheus:9090','cadvisor:8080','node-exporter:9100']

启动Prometheus
docker run -d -p 9090:9090 \
  -v /root/docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
  -v /root/docker/prometheus/node_down.yml:/etc/prometheus/node_down.yml \
  -v /root/docker/prometheus/memory_over.yml:/etc/prometheus/memory_over.yml \
  -v /root/docker/prometheus/load_over.yml:/etc/prometheus/load_over.yml \
  -h prometheus \
  --name prometheus \
  --net=my_net2 \
  prom/prometheus

通过 http://IP:9090/metrics 测试一下

在浏览器中打开 http://IP:9090 ，点击菜单 Status -> Targets

所有 Target 的 State 都是 UP，说明 Prometheus Server 能够正常获取监控数据。

报警规则配置成功在 http://XXXX:9090/alerts 可以看到报警规则已经添加到prometheus的Alerts中

测试报警功能
停掉cAdvisor容器
docker stop monitoring_cadvisor

等待一会，看是否会给你配置的邮件报警
```

# 5.运行 Grafana
```
在 host 上执行如下命令：
docker run -d -i -p 3000:3000 \
  -e "GF_SERVER_ROOT_URL=http://grafana.server.name"  \
  -e "GF_SECURITY_ADMIN_PASSWORD=secret"  \
  --net=my_net2 \
  grafana/grafana

-e "GF_SECURITY_ADMIN_PASSWORD=secret 指定了 Grafana admin用户密码 secret。

docker run -d -i -p 3000:3000 \
  -h grafana \
  --name=grafana \
  --net=my_net2 \
  grafana/grafana

 注意，这里我们使用了 --net=my_net2，这样 Grafana 可以直接与 Prometheus Server 通信。

Grafana 启动后。在浏览器中打开 http://IP:3000/  
grafana默认密码 admin admin

```

<!---
docker compose 参考link： https://grafana.com/dashboards/893


slack link
https://songjiayang.gitbooks.io/prometheus/content/alertmanager/slack.html
http://www.songjiayang.com/posts/prometheus-alert-slack-receiver
https://prometheus.io/docs/alerting/configuration/

https://appopsworkspace.slack.com

https://github.com/prometheus/alertmanager --!>